{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "psz-nf7Afzj1"
   },
   "source": [
    "# Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "sFhkPxkBm3Qb"
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "FC54oU4AmuuX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• Tensorflow version: 1.15.3\n",
      "• GPU device name: \n",
      "• Num GPUs Available: 0\n",
      "• Ampligraph version: 1.3.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ampligraph\n",
    "import pickle\n",
    "from ampligraph.evaluation import evaluate_performance\n",
    "from ampligraph.evaluation import train_test_split_no_unseen \n",
    "from ampligraph.utils import save_model\n",
    "from ampligraph.utils import restore_model\n",
    "from ampligraph.datasets import load_from_csv\n",
    "from ampligraph.latent_features import ComplEx\n",
    "# from google.colab import files\n",
    "# from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "\n",
    "print(f'• Tensorflow version: {tf.__version__}')\n",
    "print(f'• GPU device name: {tf.test.gpu_device_name()}')\n",
    "print(f'• Num GPUs Available: {len(tf.config.experimental.list_physical_devices(\"GPU\"))}')\n",
    "print(f'• Ampligraph version: {ampligraph.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DRqxRrp4nF1D"
   },
   "outputs": [],
   "source": [
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Eafwj6grSWiK"
   },
   "outputs": [],
   "source": [
    "def pickle_out(name, obj, default_path='./sub_result/'):\n",
    "    pickle_out = open(default_path + name + '.pickle','wb')\n",
    "    pickle.dump(obj, pickle_out)\n",
    "    pickle_out.close()\n",
    "    return\n",
    "\n",
    "def pickle_in(name, default_path='./sub_result/'):\n",
    "    pickle_in = open(default_path + name + '.pickle','rb')\n",
    "    obj = pickle.load(pickle_in)\n",
    "    pickle_in.close()\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r0n1C5C1fzj9"
   },
   "source": [
    "# Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "VGpstfAE4mOw"
   },
   "outputs": [],
   "source": [
    "X = load_from_csv('.', 'kg_triples_freesound.txt', sep='\\t')\n",
    "X_train = load_from_csv('./drive/My Drive', 'train_fs_re.txt', sep='\\t')\n",
    "X_test = load_from_csv('./drive/My Drive', 'test_fs_re.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wmlofZ6nSWiK"
   },
   "source": [
    "# Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i2yyNGcwXkrS"
   },
   "outputs": [],
   "source": [
    "#model = restore_model(model_name_path = 'complex_model_opt.pkl')\n",
    "#model = restore_model(model_name_path = 'complex_model_opt_mll.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tWMuYEdakrm2"
   },
   "outputs": [],
   "source": [
    "entities = np.unique(np.concatenate([X[:, 0], X[:, 2]]))\n",
    "entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RyU5GBL9fzkG"
   },
   "outputs": [],
   "source": [
    "relations = np.unique(X[:, 1])\n",
    "relations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1NTKNkSufzkI"
   },
   "source": [
    "# Defining train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9swgzKWrfzkJ"
   },
   "outputs": [],
   "source": [
    "# we create a 20% test set split\n",
    "X_train, X_test = train_test_split_no_unseen(X, test_size=int(len(X)*.2), \n",
    "                                             seed=0, allow_duplication=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CNkGiEwkfzkL"
   },
   "source": [
    "#### Saving train/test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yZ8Lh2q51GEL"
   },
   "outputs": [],
   "source": [
    "with open('./train.txt', 'w') as f:\n",
    "    for (s, p, o) in X_train:\n",
    "        f.write(s + '\\t' + p + '\\t' + o + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LYjmjQqt1Zrv"
   },
   "outputs": [],
   "source": [
    "with open('./test.txt', 'w') as f:\n",
    "    for (s, p, o) in X_test:\n",
    "        f.write(s + '\\t' + p + '\\t' + o + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y46h5VjufzkL"
   },
   "outputs": [],
   "source": [
    "print('Train set size: ', X_train.shape)\n",
    "print('Test set size: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qb2TEx3ESWiK"
   },
   "source": [
    "# Training with tuned params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "q0VtdRQdfzkW"
   },
   "outputs": [],
   "source": [
    "EmbeddingMethod = ComplEx\n",
    "positives_filter = X\n",
    "\n",
    "model = EmbeddingMethod(batches_count=40, \n",
    "                seed=0, \n",
    "                epochs=1000, \n",
    "                k=350, \n",
    "                eta=5,\n",
    "                optimizer='adam', \n",
    "                optimizer_params={'lr':1e-5},\n",
    "                loss='multiclass_nll', \n",
    "                regularizer='LP', \n",
    "                regularizer_params={'p':3, 'lambda':1e-7}, \n",
    "                verbose=False)\n",
    "\n",
    "with tf.device('/device:GPU:0'):\n",
    "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "    model.fit(X_train, early_stopping = False)\n",
    "\n",
    "save_model(model, model_name_path='complex_model_opt_fs.pkl')\n",
    "#files.download('complex_model_opt.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DK0-fE5RSWiK"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-mGFm0Ikb-R8"
   },
   "outputs": [],
   "source": [
    "entities_subset = np.unique(X_test[X_test[:, 1]=='downloaded', 2])\n",
    "positives_filter = X\n",
    "with tf.device('/device:GPU:0'):\n",
    "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "    ranks = evaluate_performance(X_test, \n",
    "                              model=model,\n",
    "                              entities_subset=entities_subset,\n",
    "                              filter_triples=positives_filter,\n",
    "                              corrupt_side='s,o',\n",
    "                              #use_default_protocol=True,\n",
    "                              verbose=True)\n",
    "    \n",
    "ranks_name = 'ranks_complex_opt_fs'\n",
    "pickle_out(ranks_name, ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = pickle_in('ranks_complex_opt_fs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "qEtKfyCQfzkm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR: 0.53\n",
      "Hits@10: 0.53\n",
      "Hits@3: 0.53\n",
      "Hits@1: 0.52\n"
     ]
    }
   ],
   "source": [
    "from ampligraph.evaluation import mr_score, mrr_score, hits_at_n_score\n",
    "\n",
    "mrr = mrr_score(ranks)\n",
    "print(\"MRR: %.2f\" % (mrr))\n",
    "\n",
    "hits_10 = hits_at_n_score(ranks, n=10)\n",
    "print(\"Hits@10: %.2f\" % (hits_10))\n",
    "hits_3 = hits_at_n_score(ranks, n=3)\n",
    "print(\"Hits@3: %.2f\" % (hits_3))\n",
    "hits_1 = hits_at_n_score(ranks, n=1)\n",
    "print(\"Hits@1: %.2f\" % (hits_1))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "kge_final_fs.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
